# 08 - Deployments

https://wangwei1237.github.io/Kubernetes-in-Action-Second-Edition/docs/Managing_Pods_with_Deployments.html

Deployment is the standard solution to **deploy stateless applications** in Kb8s 
in **declarative approach** (the desired status is declared applying a **configuration change** and the cluster applies the 
required actions to reach the desired state).

## Deployments and ReplicaSets

They handles replicas of pods not directly but via a `Replicaset`

[busybox-deployment.yaml](config%2Fdeployments%2Fbusybox-deployment.yaml)

```shell
kubectl get deploy --show-labels
NAME                 READY   UP-TO-DATE   AVAILABLE   AGE   LABELS
busybox-deployment   3/3     3            3           39m   app=busybox
```

If we analyze the generated replicaset

```shell
$ kubectl describe rs

Name:           busybox-deployment-9869f9495
Selector:       app=busybox,pod-template-hash=9869f9495
Labels:         app=busybox #deployment
                pod-template-hash=9869f9495 #pod template hash
...
Replicas:       3 current / 3 desired
...
Pod Template:
  Labels:  app=busybox
           pod-template-hash=9869f9495
```

> We see that every **Deployment state generates a dedicated replicaset instance**, each with its **hash value** which is applied
> to the **rs name** and as a **label to each pod** under its control.

The pods are generated by the rs
```shell
$ kubectl get pods --show-labels

NAME                                 READY   STATUS    RESTARTS   AGE   LABELS
busybox-deployment-9869f9495-6pks8   1/1     Running   0          44m   app=busybox,pod-template-hash=9869f9495
busybox-deployment-9869f9495-7qng8   1/1     Running   0          44m   app=busybox,pod-template-hash=9869f9495
busybox-deployment-9869f9495-ntxf2   1/1     Running   0          44m   app=busybox,pod-template-hash=9869f9495
```

The pods have:
- name format: `<deployment_name>-<rs_hash>-<specific_pod_hash>`
- labels:
    - `<app=busybox>` set by the deployment
    - `pod-template-hash=9869f9495` the rs specific label, links the pod to the rs

## Scaling a Deployment

```shell
$ kubectl scale deploy busybox-deployment --replicas 5

$ kubectl get pods --show-labels --watch
NAME                                 READY   STATUS              RESTARTS   AGE   LABELS
busybox-deployment-9869f9495-6pks8   1/1     Running             0          67m   app=busybox,pod-template-hash=9869f9495
busybox-deployment-9869f9495-7qng8   1/1     Running             0          67m   app=busybox,pod-template-hash=9869f9495
busybox-deployment-9869f9495-7tt2x   0/1     ContainerCreating   0          3s    app=busybox,pod-template-hash=9869f9495
busybox-deployment-9869f9495-8w5dn   0/1     ContainerCreating   0          3s    app=busybox,pod-template-hash=9869f9495
busybox-deployment-9869f9495-ntxf2   1/1     Running             0          67m   app=busybox,pod-template-hash=9869f9495
busybox-deployment-9869f9495-7tt2x   1/1     Running             0          21s   app=busybox,pod-template-hash=9869f9495
busybox-deployment-9869f9495-8w5dn   1/1     Running             0          22s   app=busybox,pod-template-hash=9869f9495
```

## Updating a deployment

When we want to update the image used in the deployment, we simply change it in the deployment.

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: busybox-deployment
spec:
  template:
    spec:
      containers:
        - name: busybox
          #image: busybox:stable 
          image: busybox:latest 
```
### New Replicaset generation
If the `PodTemplate` section of the deployment changes, the **deployment controller** will create a **new replica set**,
`usybox-deployment-5959cb9df5` replace the old one `set busybox-deployment-9869f9495`.



```shell
$kubectl describe deploy

Conditions:
  Type           Status  Reason
  ----           ------  ------
  Available      True    MinimumReplicasAvailable
  Progressing    True    NewReplicaSetAvailable
OldReplicaSets:  busybox-deployment-9869f9495 (0/0 replicas created)
NewReplicaSet:   busybox-deployment-5959cb9df5 (3/3 replicas created)
Events:
  Type    Reason             Age    From                   Message
  ----    ------             ----   ----                   -------
  Normal  ScalingReplicaSet  66s    deployment-controller  Scaled up replica set busybox-deployment-5959cb9df5 from 0 to 1
  Normal  ScalingReplicaSet  66s    deployment-controller  Scaled down replica set busybox-deployment-9869f9495 from 3 to 2
  Normal  ScalingReplicaSet  66s    deployment-controller  Scaled up replica set busybox-deployment-5959cb9df5 from 1 to 2
  Normal  ScalingReplicaSet  63s    deployment-controller  Scaled down replica set busybox-deployment-9869f9495 from 2 to 1
  Normal  ScalingReplicaSet  63s    deployment-controller  Scaled up replica set busybox-deployment-5959cb9df5 from 2 to 3
  Normal  ScalingReplicaSet  62s    deployment-controller  Scaled down replica set busybox-deployment-9869f9495 from 1 to 0
```

The sequence of events above follows a specific update strategy

## Update strategies

The deployment allows two update strategies: `rollingUpdate` and `recreate`

### Recreate update strategy

Simple strategy which deletes all the previous pods at the same time and, when all
of them are deleted, it creates the new ones.

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: busybox-deployment

spec:
  ...
  strategy:
    type: Recreate
```

This strategy makes the **application unavailable after the old pods are deleted**.

![14.4.png](images%2Fdeployments%2F14.4.png)

**Pro**:
* application state entirely renewed

**Cons**:
* downtime that depends on both shutdown and boot duration of the application

### `RollingUpdate` strategy - Ramped slow rollout

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: busybox-deployment
spec:
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxSurge: 0
      maxUnavailable: 1
  replicas: 3
  selector:
    ...
```
The fields allow for fine-grained control over the update speed and availability during the rollout.
`maxSurge`: This field specifies the **maximum number of pods that can be created beyond the desired number of replicas during the update**. It can be an absolute number or a percentage of the desired replicas. For example, if maxSurge is set to 1, the deployment can temporarily have one extra pod running during the update.
`maxUnavailable`: This field specifies the **maximum number of pods that can be unavailable (either not running or not yet ready) during the update**. Like maxSurge, it can be an absolute number or a percentage of the desired replicas. For instance, if `maxUnavailable` is set to 1, the deployment ensures that at least one old pod remains running at any given time during the update. 

During a rolling update, Kubernetes first creates new pods based on the `maxSurge` setting. 
Then, it terminates old pods based on the `maxUnavailable` setting.
The process continues until all old pods are replaced with new ones.

![kubernetes-deployment-strategy-ramped-1.webp](images%2Fdeployments%2Fkubernetes-deployment-strategy-ramped-1.webp)

For example, a deployment with maxSurge: 25% and maxUnavailable: 25% will gradually update the application, 
ensuring that at least 75% of the pods are always available, and the deployment won't add more than 25% extra pods at any given time.

Here is an example with `MaxSurge=0, maxUnavailable=1`

![14.7.png](images%2Fdeployments%2F14.7.png)

Now `MaxSurge=1, maxUnavailable=0`

![14.8.png](images%2Fdeployments%2F14.8.png)

Now `maxSurge=1, maxUnavailable=1`

![14.9.png](images%2Fdeployments%2F14.9.png)

**Pro**:

* no service discountinuity
* version is slowly released across instances
* convenient for stateful applications that can handle rebalancing of the data

**Cons**:

* rollout/rollback can take time
* supporting multiple APIs is hard
* no control over traffic (**it is not guaranteed what pod will serve a request during the update**)

### "Blue" "Green" deployment - Avoid API versioning issues

Different from the ramped deployment, **the "green" version of the application is deployed alongside the "blue" version**. 
After testing that the new version meets the requirements, **we update the Kubernetes Service object that plays the role of load balancer to send traffic to the new version** 
by replacing the version label in the selector field.

[blue-green-deployment-test.sh](config%2Fdeployments%2Fblue-green%2Fblue-green-deployment-test.sh)

**Pro**:

- instant rollout/rollback
- avoid versioning issue, change the entire cluster state in one go

**Cons**:

- requires double the resources
- proper test of the entire platform should be done before releasing to production
- handling stateful applications can be hard

### Canary deployment - let the consumer do the testing

A canary deployment consists of **gradually shifting production traffic from version A to version B**. 
Usually the traffic is split based on weight. For example, 90 percent of the requests go to version A, 10 percent go to version B.

This technique is mostly used **when the tests are lacking or not reliable or if there is little confidence about the stability of the new release** 
on the platform.

- Two deployments
  - One with version 1 with the majority of pods (ex 4)
  - The other with version 2 with a limited set of pods (ex 1)
- A service
  - selects pods from both deployments
  - works as a load balancer forwarding percentage of traffic based on the replicas (25% calls on V2)
- Adjusting the deployment replicas allow change the percentage of traffic to one specific version

After applying the file
[canary-deployment-test.sh](config%2Fdeployments%2Fcanary%2Fcanary-deployment-test.sh)

We can make curl calls to the service, from a pod inside the cluster to check the service pod percentages

```bash
kubectl run curl-client --rm -i --tty --image=curlimages/curl -- /bin/sh

$ for i in {1..10}; do kubectl run curl-client --rm -i --tty --image=curlimages/curl -- curl backend.default.svc.cluster.local:3000 delete pod curl-client 
 
delete pod <pod-name>
```

### A/B testing - best for feature testing on a subset of users



https://blog.container-solutions.com/kubernetes-deployment-strategies#kubernetes-canary








![kubernetes-deployment-strategy-blue-green-1.png](images%2Fdeployments%2Fkubernetes-deployment-strategy-blue-green-1.png)


https://spot.io/resources/kubernetes-autoscaling/8-kubernetes-deployment-strategies/#b9


https://blog.container-solutions.com/kubernetes-deployment-strategies


https://spot.io/resources/kubernetes-autoscaling/8-kubernetes-deployment-strategies/

https://www.groundcover.com/blog/kubernetes-deployment-strategies#:~:text=Ramped%20slow%20rollout,a%20pause%20between%20each%20update.

## Horizontal pod outscaling

https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/

